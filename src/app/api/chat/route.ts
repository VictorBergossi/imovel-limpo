import { NextRequest, NextResponse } from 'next/server'
import OpenAI from 'openai'

const OPENAI_API_KEY = process.env.OPENAI_API_KEY || ''
const openai = new OpenAI({ apiKey: OPENAI_API_KEY })

// Fun√ß√£o de delay para retry
const delay = (ms: number) => new Promise(res => setTimeout(res, ms))

interface ChatMessage {
  role: 'user' | 'assistant'
  content: string
}

// Fun√ß√£o para enviar mensagem com retry autom√°tico
async function sendMessageWithRetry(
  messages: OpenAI.Chat.Completions.ChatCompletionMessageParam[],
  maxRetries = 3
) {
  for (let attempt = 1; attempt <= maxRetries; attempt++) {
    try {
      const result = await openai.chat.completions.create({
        model: 'gpt-4o-mini',
        messages,
        max_tokens: 2048
      })
      return result
    } catch (error: unknown) {
      const err = error as { status?: number; message?: string }
      
      if (err.status === 429 || err.message?.includes('429')) {
        console.log(`Limite atingido (tentativa ${attempt}/${maxRetries}), aguardando 25 segundos...`)
        
        if (attempt < maxRetries) {
          await delay(25000)
          continue
        }
      }
      
      throw error
    }
  }
  
  throw new Error('N√∫mero m√°ximo de tentativas excedido')
}

export async function POST(request: NextRequest) {
  try {
    const body = await request.json()
    const { message, history = [] } = body as { message: string; history: ChatMessage[] }

    if (!message || typeof message !== 'string') {
      return NextResponse.json(
        { error: 'Mensagem √© obrigat√≥ria' },
        { status: 400 }
      )
    }

    // Contexto do sistema
    const systemPrompt = `Voc√™ √© o assistente virtual do Im√≥vel Limpo, uma plataforma que analisa matr√≠culas de im√≥veis e certid√µes para corretores imobili√°rios.

Seu papel √©:
1. Receber e entender matr√≠culas de im√≥veis que os usu√°rios enviam
2. Explicar o processo de an√°lise
3. Responder d√∫vidas sobre documenta√ß√£o imobili√°ria
4. Ser amig√°vel e profissional

Quando o usu√°rio enviar um texto que parece ser uma matr√≠cula de im√≥vel (cont√©m palavras como "matr√≠cula", "registro", "cart√≥rio", "R$", "im√≥vel", "averba√ß√£o", propriet√°rio, CPF, CNPJ, etc), voc√™ deve:
1. Confirmar que recebeu a matr√≠cula
2. Informar que vai iniciar a an√°lise
3. Responder com a seguinte estrutura JSON no final da sua mensagem:
{"action": "ANALYZE_MATRICULA", "hasMatricula": true}

Se o usu√°rio enviar uma mensagem normal (d√∫vida, sauda√ß√£o, etc), responda normalmente de forma amig√°vel.

IMPORTANTE: 
- Responda SEMPRE em portugu√™s do Brasil
- Seja conciso e objetivo
- Se identificar uma matr√≠cula, SEMPRE inclua o JSON de a√ß√£o no final
- Voc√™ √© simp√°tico mas profissional`

    // Monta o hist√≥rico para o chat
    const messages: OpenAI.Chat.Completions.ChatCompletionMessageParam[] = [
      { role: 'system', content: systemPrompt },
      ...history.map(msg => ({
        role: msg.role as 'user' | 'assistant',
        content: msg.content
      })),
      { role: 'user', content: message }
    ]

    const result = await sendMessageWithRetry(messages)
    const textResponse = result.choices[0]?.message?.content || ''

    // Contagem de tokens
    const inputTokens = result.usage?.prompt_tokens || 0
    const outputTokens = result.usage?.completion_tokens || 0
    
    console.log(`üìä Chat Tokens - Input: ${inputTokens}, Output: ${outputTokens}, Total: ${inputTokens + outputTokens}`)

    if (!textResponse) {
      throw new Error('Resposta vazia do OpenAI')
    }

    // Verifica se h√° a√ß√£o de an√°lise
    const actionMatch = textResponse.match(/\{"action":\s*"ANALYZE_MATRICULA".*?\}/)
    let shouldAnalyze = false
    let cleanResponse = textResponse

    if (actionMatch) {
      try {
        const action = JSON.parse(actionMatch[0])
        shouldAnalyze = action.hasMatricula === true
        // Remove o JSON da resposta vis√≠vel
        cleanResponse = textResponse.replace(actionMatch[0], '').trim()
      } catch {
        // Ignora erros de parse
      }
    }

    return NextResponse.json({
      success: true,
      response: cleanResponse,
      shouldAnalyze,
      matriculaText: shouldAnalyze ? message : null,
      tokenUsage: {
        input: inputTokens,
        output: outputTokens,
        total: inputTokens + outputTokens
      }
    })
  } catch (error: unknown) {
    const err = error as { message?: string }
    console.error('Erro no chat:', error)
    
    if (err.message?.includes('429')) {
      return NextResponse.json(
        { error: 'Limite de requisi√ß√µes atingido. Aguarde alguns segundos e tente novamente.' },
        { status: 429 }
      )
    }
    
    return NextResponse.json(
      { error: 'Erro ao processar mensagem. Tente novamente.' },
      { status: 500 }
    )
  }
}
